"""
Advanced Privacy Attack Simulation Module.
Implements state-of-the-art privacy attacks including:
- Canary extraction attacks
- Loss-based membership inference
- Multiple extraction strategies
- Statistical significance testing
"""

import torch
import torch.nn.functional as F
import json
import random
import numpy as np
from pathlib import Path
from transformers import GPT2Tokenizer, GPT2LMHeadModel
from tqdm import tqdm
from typing import List, Dict, Tuple, Optional
from collections import defaultdict
from scipy import stats

import sys
sys.path.append(str(Path(__file__).parent.parent))
from config import (
    DATA_DIR, MODELS_DIR, ATTACK_PROMPTS, 
    NUM_ATTACK_SAMPLES, MAX_LENGTH, RANDOM_SEED,
    ATTACK_MAX_LENGTH, ATTACK_TEMPERATURE, ATTACK_TOP_K,
    ATTACK_TOP_P, ATTACK_NUM_SEQUENCES
)


class AdvancedPrivacyAttacker:
    """
    Advanced privacy attacker with multiple attack strategies.
    Implements state-of-the-art attacks from privacy research.
    """
    
    def __init__(self, model_path, device=None):
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # Load model and tokenizer
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_path)
        self.model = GPT2LMHeadModel.from_pretrained(model_path)
        self.model.to(self.device)
        self.model.eval()
        
        print(f"Loaded model from {model_path}")
    
    def load_private_records(self, filename='train_patient_records.json'):
        """Load tracked private records with auto-detection"""
        # Try healthcare records first
        records_file = DATA_DIR / filename
        if not records_file.exists():
            # Fallback to generic records
            records_file = DATA_DIR / 'train_private_records.json'
        
        if not records_file.exists():
            raise FileNotFoundError(f"No records file found at {records_file}")
        
        with open(records_file, 'r') as f:
            records = json.load(f)
        
        print(f"üìã Loaded {len(records)} private records from {records_file.name}")
        return records
    
    def compute_loss(self, text: str) -> float:
        """Compute language modeling loss for a given text"""
        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=MAX_LENGTH).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(**inputs, labels=inputs['input_ids'])
            loss = outputs.loss.item()
        
        return loss
    
    def canary_extraction_attack(self, canaries: List[Dict], num_samples: int = None) -> Dict:
        """
        Canary extraction attack: Insert unique canaries and check if model memorizes them.
        This is a stronger attack than prompt extraction.
        """
        print("\nüéØ Running Canary Extraction Attack...")
        print("   (Inserting unique canaries and checking memorization)")
        
        if num_samples is None:
            num_samples = min(len(canaries), NUM_ATTACK_SAMPLES)
        
        sampled_canaries = random.sample(canaries, num_samples)
        
        extraction_stats = {
            'total_canaries': len(sampled_canaries),
            'extracted_canaries': 0,
            'extraction_rate': 0.0,
            'canary_details': []
        }
        
        for canary in tqdm(sampled_canaries, desc="Testing canaries"):
            canary_text = canary['text']
            canary_phi = canary.get('phi', {})
            
            # Try multiple extraction strategies
            extracted = False
            
            # Strategy 1: Direct prompt extraction
            for prompt in ATTACK_PROMPTS[:5]:  # Use subset for speed
                generated = self.generate_text(prompt, max_length=ATTACK_MAX_LENGTH, num_return_sequences=1)
                for gen_text in generated:
                    if self._check_canary_match(gen_text, canary_text, canary_phi):
                        extracted = True
                        break
                if extracted:
                    break
            
            # Strategy 2: Partial text completion
            if not extracted:
                # Use first part of canary as prompt
                words = canary_text.split()
                if len(words) > 5:
                    partial_prompt = ' '.join(words[:len(words)//2])
                    generated = self.generate_text(partial_prompt, max_length=ATTACK_MAX_LENGTH, num_return_sequences=2)
                    for gen_text in generated:
                        if self._check_canary_match(gen_text, canary_text, canary_phi):
                            extracted = True
                            break
            
            if extracted:
                extraction_stats['extracted_canaries'] += 1
                extraction_stats['canary_details'].append({
                    'canary_id': canary.get('id', 'unknown'),
                    'extracted': True,
                    'phi_fields': list(canary_phi.keys())
                })
        
        extraction_stats['extraction_rate'] = (
            extraction_stats['extracted_canaries'] / extraction_stats['total_canaries'] * 100
            if extraction_stats['total_canaries'] > 0 else 0.0
        )
        
        print(f"\nüìä Canary Extraction Results:")
        print(f"   - Extraction Rate: {extraction_stats['extraction_rate']:.2f}%")
        print(f"   - Extracted Canaries: {extraction_stats['extracted_canaries']}/{extraction_stats['total_canaries']}")
        
        return {
            'attack_type': 'canary_extraction',
            **extraction_stats
        }
    
    def _check_canary_match(self, generated_text: str, canary_text: str, canary_phi: Dict) -> bool:
        """Check if generated text matches canary"""
        generated_lower = generated_text.lower()
        canary_lower = canary_text.lower()
        
        # Check for exact match or high similarity
        if canary_lower in generated_lower or generated_lower in canary_lower:
            return True
        
        # Check for PHI matches
        for field, value in canary_phi.items():
            if isinstance(value, str):
                if value.lower() in generated_lower:
                    return True
        
        # Check for high word overlap (>70%)
        canary_words = set(canary_lower.split())
        gen_words = set(generated_lower.split())
        if len(canary_words) > 0:
            overlap = len(canary_words & gen_words) / len(canary_words)
            if overlap > 0.7:
                return True
        
        return False
    
    def loss_based_membership_inference(self, private_records: List[Dict], 
                                       num_samples: int = None,
                                       num_reference: int = 100) -> Dict:
        """
        Loss-based membership inference attack.
        Members typically have lower loss than non-members.
        """
        print("\nüîç Running Loss-Based Membership Inference Attack...")
        print("   (Members typically have lower loss than non-members)")
        
        if num_samples is None:
            num_samples = min(len(private_records), NUM_ATTACK_SAMPLES)
        
        # Sample members
        members = random.sample(private_records, num_samples)
        
        # Get reference samples (non-members) - use generic medical text
        reference_texts = self._get_reference_texts(num_reference)
        
        # Compute losses
        member_losses = []
        reference_losses = []
        
        print("   Computing losses for members...")
        for record in tqdm(members, desc="Members"):
            text = record.get('text', '')
            if text:
                loss = self.compute_loss(text)
                member_losses.append(loss)
        
        print("   Computing losses for reference samples...")
        for text in tqdm(reference_texts, desc="Reference"):
            loss = self.compute_loss(text)
            reference_losses.append(loss)
        
        # Statistical analysis
        member_mean = np.mean(member_losses)
        reference_mean = np.mean(reference_losses)
        
        # Threshold: members have lower loss
        threshold = np.percentile(reference_losses, 50)  # Median of reference
        
        # Classify members
        correct_inferences = sum(1 for loss in member_losses if loss < threshold)
        inference_rate = (correct_inferences / len(member_losses)) * 100 if member_losses else 0
        
        # Statistical significance test
        if len(member_losses) > 1 and len(reference_losses) > 1:
            t_stat, p_value = stats.ttest_ind(member_losses, reference_losses, alternative='less')
        else:
            t_stat, p_value = 0, 1.0
        
        results = {
            'attack_type': 'loss_based_membership_inference',
            'inference_rate': inference_rate,
            'member_mean_loss': member_mean,
            'reference_mean_loss': reference_mean,
            'loss_difference': reference_mean - member_mean,
            'threshold': threshold,
            'correct_inferences': correct_inferences,
            'total_members': len(member_losses),
            't_statistic': float(t_stat),
            'p_value': float(p_value),
            'statistically_significant': p_value < 0.05
        }
        
        print(f"\nüìä Loss-Based Membership Inference Results:")
        print(f"   - Inference Rate: {inference_rate:.2f}%")
        print(f"   - Member Mean Loss: {member_mean:.4f}")
        print(f"   - Reference Mean Loss: {reference_mean:.4f}")
        print(f"   - Loss Difference: {results['loss_difference']:.4f}")
        print(f"   - Statistically Significant: {results['statistically_significant']} (p={p_value:.4f})")
        
        return results
    
    def _get_reference_texts(self, num_samples: int) -> List[str]:
        """Get reference texts (non-members) for comparison"""
        # Load generic medical texts from training data
        data_file = DATA_DIR / "train_data.txt"
        reference_texts = []
        
        if data_file.exists():
            with open(data_file, 'r', encoding='utf-8') as f:
                all_texts = [line.strip() for line in f if line.strip()]
            
            # Filter out texts that look like they contain PHI
            generic_texts = [
                text for text in all_texts 
                if not any(phi_indicator in text.lower() for phi_indicator in 
                          ['mrn-', 'ssn', '@example', 'patient:', 'diagnosis:'])
            ]
            
            reference_texts = random.sample(generic_texts, min(num_samples, len(generic_texts)))
        
        # If not enough, generate generic medical text
        while len(reference_texts) < num_samples:
            reference_texts.append(
                "General health information: Regular exercise and balanced diet are important for maintaining good health."
            )
        
        return reference_texts[:num_samples]
    
    def multi_strategy_extraction_attack(self, private_records: List[Dict],
                                        num_samples: int = None) -> Dict:
        """
        Multi-strategy extraction attack combining multiple techniques.
        """
        print("\nüéØ Running Multi-Strategy Extraction Attack...")
        
        if num_samples is None:
            num_samples = min(len(private_records), NUM_ATTACK_SAMPLES)
        
        sampled_records = random.sample(private_records, num_samples)
        
        strategy_results = {
            'direct_prompt': {'success': 0, 'total': 0},
            'partial_completion': {'success': 0, 'total': 0},
            'context_based': {'success': 0, 'total': 0},
            'overall': {'success': 0, 'total': len(sampled_records)}
        }
        
        for record in tqdm(sampled_records, desc="Multi-strategy attack"):
            record_text = record.get('text', '')
            phi_fields = self._extract_phi_fields(record)
            
            extracted = False
            
            # Strategy 1: Direct prompt extraction
            strategy_results['direct_prompt']['total'] += 1
            for prompt in ATTACK_PROMPTS[:7]:
                generated = self.generate_text(prompt, max_length=ATTACK_MAX_LENGTH, num_return_sequences=1)
                for gen_text in generated:
                    if self._check_phi_leakage(gen_text, phi_fields):
                        strategy_results['direct_prompt']['success'] += 1
                        extracted = True
                        break
                if extracted:
                    break
            
            # Strategy 2: Partial completion
            if not extracted:
                strategy_results['partial_completion']['total'] += 1
                words = record_text.split()
                if len(words) > 5:
                    partial = ' '.join(words[:len(words)//2])
                    generated = self.generate_text(partial, max_length=ATTACK_MAX_LENGTH, num_return_sequences=2)
                    for gen_text in generated:
                        if self._check_phi_leakage(gen_text, phi_fields):
                            strategy_results['partial_completion']['success'] += 1
                            extracted = True
                            break
            
            # Strategy 3: Context-based (using medical context)
            if not extracted:
                strategy_results['context_based']['total'] += 1
                context_prompts = [
                    "Medical record for patient",
                    "Patient information:",
                    "Clinical note:",
                ]
                for prompt in context_prompts:
                    generated = self.generate_text(prompt, max_length=ATTACK_MAX_LENGTH, num_return_sequences=2)
                    for gen_text in generated:
                        if self._check_phi_leakage(gen_text, phi_fields):
                            strategy_results['context_based']['success'] += 1
                            extracted = True
                            break
                    if extracted:
                        break
            
            if extracted:
                strategy_results['overall']['success'] += 1
        
        # Calculate rates
        for strategy in strategy_results:
            if strategy_results[strategy]['total'] > 0:
                rate = (strategy_results[strategy]['success'] / 
                       strategy_results[strategy]['total']) * 100
                strategy_results[strategy]['rate'] = rate
            else:
                strategy_results[strategy]['rate'] = 0.0
        
        overall_rate = (strategy_results['overall']['success'] / 
                        strategy_results['overall']['total']) * 100
        
        print(f"\nüìä Multi-Strategy Extraction Results:")
        print(f"   - Overall Extraction Rate: {overall_rate:.2f}%")
        print(f"   - Direct Prompt: {strategy_results['direct_prompt']['rate']:.2f}%")
        print(f"   - Partial Completion: {strategy_results['partial_completion']['rate']:.2f}%")
        print(f"   - Context-Based: {strategy_results['context_based']['rate']:.2f}%")
        
        return {
            'attack_type': 'multi_strategy_extraction',
            'overall_rate': overall_rate,
            'strategy_results': strategy_results
        }
    
    def _extract_phi_fields(self, record: Dict) -> Dict:
        """Extract PHI fields from record"""
        phi = {}
        for key in ['name', 'email', 'ssn', 'phone', 'mrn', 'dob', 'condition', 'medication']:
            if key in record:
                phi[key] = record[key]
        return phi
    
    def _check_phi_leakage(self, generated_text: str, phi_fields: Dict) -> bool:
        """Check if generated text contains any PHI fields"""
        generated_lower = generated_text.lower()
        
        for field, value in phi_fields.items():
            if isinstance(value, str):
                value_lower = value.lower()
                # Exact match
                if value_lower in generated_lower:
                    return True
                # Partial match for names
                if field == 'name':
                    name_words = value_lower.split()
                    if any(word in generated_lower for word in name_words if len(word) > 2):
                        return True
        
        return False
    
    def generate_text(self, prompt: str, max_length: int = None, 
                     num_return_sequences: int = None) -> List[str]:
        """Generate text from prompt"""
        if max_length is None:
            max_length = ATTACK_MAX_LENGTH
        if num_return_sequences is None:
            num_return_sequences = ATTACK_NUM_SEQUENCES
            
        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_length=max_length,
                min_length=max(15, len(inputs['input_ids'][0]) + 10),
                num_return_sequences=num_return_sequences,
                do_sample=True,
                top_k=ATTACK_TOP_K,
                top_p=ATTACK_TOP_P,
                temperature=ATTACK_TEMPERATURE,
                repetition_penalty=1.1,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=None,
                no_repeat_ngram_size=2
            )
        
        generated_texts = [
            self.tokenizer.decode(output, skip_special_tokens=True) 
            for output in outputs
        ]
        
        return generated_texts
    
    def run_all_advanced_attacks(self, canaries: Optional[List[Dict]] = None) -> Dict:
        """Run all advanced privacy attacks"""
        print("\n" + "="*70)
        print("üéØ ADVANCED PRIVACY ATTACK SIMULATION")
        print("="*70)
        
        # Load private records
        private_records = self.load_private_records()
        
        results = {}
        
        # 1. Loss-based membership inference
        results['loss_based_membership'] = self.loss_based_membership_inference(
            private_records, num_samples=NUM_ATTACK_SAMPLES
        )
        
        # 2. Multi-strategy extraction
        results['multi_strategy_extraction'] = self.multi_strategy_extraction_attack(
            private_records, num_samples=NUM_ATTACK_SAMPLES
        )
        
        # 3. Canary extraction (if canaries provided)
        if canaries:
            results['canary_extraction'] = self.canary_extraction_attack(canaries)
        
        # Calculate overall privacy risk
        leakage_rate = results['multi_strategy_extraction']['overall_rate']
        inference_rate = results['loss_based_membership']['inference_rate']
        
        # Weighted combination
        overall_risk = (leakage_rate * 0.6 + inference_rate * 0.4)
        
        results['overall_privacy_risk'] = overall_risk
        
        print("\n" + "="*70)
        print(f"üö® Overall Privacy Risk Score: {overall_risk:.2f}%")
        print("="*70)
        
        return results

